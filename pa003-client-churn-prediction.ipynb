{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:55:55.370734Z",
     "start_time": "2020-11-18T21:55:55.367552Z"
    },
    "collapsed": "true"
   },
   "source": [
    "# Business Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Desafio **\n",
    "Criar um modelo de alta performance na identificação de clientes em churn.\n",
    "\n",
    "Sobre a Empresa:\n",
    "A TopBottonBank é um novo banco com atuação na europa.\n",
    " \n",
    "**Entregável:**\n",
    "Ao final da sua consultoria, você precisa entregar ao CEO da TopBottomBank um modelo em produção, que receberá uma base de clientes via API e desenvolverá essa base “scorada”, ou seja, um coluna à mais com a probabilidade de cada cliente entrar em churn.\n",
    "\n",
    "Perguntas a serem respondidas no report final:\n",
    "1-Qual a taxa de Churn atual da empresa?\n",
    "2-Como a taxa de Churn varia por mês?\n",
    "3-Qual a Performance do modelo em classificar os clientes como churns?\n",
    "4-Qual o Faturamento da empresa, se ela impedir que os clientes de entrar em Churn através do seu modelo?\n",
    "5-Qual o valor de um cupom de desconto você daria para o cliente, a fim de evitar churn? E qual o custo total desse incentivo para a empresa?\n",
    "\n",
    "**Index:**\n",
    " - 1.0 Problema de Negócio\n",
    " - 1.1 Importações de bibliotecas\n",
    " - 2.0 Coleta de Dados\n",
    " - 3.0 Descrição dos Dados\n",
    " - 4.0 Limpeza de dados\n",
    " - 5.0 Feature Engineering\n",
    " - 6.0 EDA\n",
    " - 7.0 Data Preparation\n",
    " - 8.0 Feature Selection\n",
    " - 9.0 Model Selection\n",
    " - 10.0 Tunning/Treinamento do modelo\n",
    " - 11.0 API\n",
    " \n",
    "**Estrátegia:**\n",
    "\n",
    "3.0 Coleta de Dados:\n",
    "Coletar os dados utilizando pd.read_csv().\n",
    "\n",
    "4.0 Descrição dos Dados:\n",
    "- Descrever as seguintes infos por feature: percentual de missing, valores únicos,     percentual de valores únicos, tipos de dados, skew, kurtosis.\n",
    "- Descrever Gender vs Exited.\n",
    "- Descrever Geography vs Exited.\n",
    "- Descrever HasCrCard vs Exited \n",
    "- Descrever IsActiveMember vs Exited\n",
    "- Descrever a variável 'type' com relação ao target.\n",
    "- Descrever outras variáveis conforme for pertinente.\n",
    "- Investigar a presença de Outliers.\n",
    "\n",
    "5.0 Limpeza de dados:\n",
    "- Investigar e eliminar os outliers\n",
    "\n",
    "\n",
    "6.0 Feature Engineering\n",
    "\n",
    "7.0 EDA\n",
    "\n",
    "8.0 Teste de Hipoteses\n",
    "\n",
    "9.0 Split Data\n",
    "\n",
    "10.0 Data Preparation\n",
    "\n",
    "11.0 Balanciamento dos Dados\n",
    "\n",
    "12.0 Feature Selection\n",
    "\n",
    "13.0 Model Selection\n",
    "\n",
    "14.0 Tunning/Treinamento do modelo\n",
    "\n",
    "15.0 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T14:20:17.129003Z",
     "start_time": "2020-11-28T14:20:17.118634Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pointbiserialr\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "from BorutaShap import BorutaShap\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:08:53.076668Z",
     "start_time": "2020-11-28T13:08:53.059513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def multi_boxplots(df, variables: list) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Function to check for outliers visually through a boxplot\n",
    "\n",
    "    data: DataFrame\n",
    "\n",
    "    variable: list of numerical variables\n",
    "    \"\"\"\n",
    "\n",
    "    # set of initial plot posistion\n",
    "    n = 1\n",
    "\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    for column in df[variables].columns:\n",
    "        plt.subplot(3, 3, n)\n",
    "        _ = sns.boxplot(x=column, data=df)\n",
    "        n += 1\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def Myheat_map(dataset, variaveis):\n",
    "\n",
    "    df_corr = dataset[variaveis].corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    # mask\n",
    "    mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
    "    # adjust mask and df\n",
    "    mask = mask[1:, :-1]\n",
    "    corr = df_corr.iloc[1:,:-1].copy()\n",
    "    # color map\n",
    "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "\n",
    "    # plot heatmap\n",
    "    sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\",\n",
    "                   linewidths=5, cmap=cmap, vmin=-1, vmax=1, \n",
    "                   cbar_kws={\"shrink\": .8}, square=True)\n",
    "    yticks = [i.upper() for i in corr.index]\n",
    "    xticks = [i.upper() for i in corr.columns]\n",
    "    plt.yticks(plt.yticks()[0], labels=yticks, rotation=0)\n",
    "    plt.xticks(plt.xticks()[0], labels=xticks, rotation=20)\n",
    "\n",
    "    # title\n",
    "    title = 'CORRELATION MATRIX\\n'\n",
    "    plt.title(title, loc='left', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def cramer_v(var_x, var_y):\n",
    "    \"\"\"\n",
    "    Function to calculate the Cramers v correlation.\n",
    "\n",
    "    \"\"\"\n",
    "    # builds contigency matrix (or confusion matrix)\n",
    "    confusion_matrix_v = pd.crosstab(var_x, var_y).values\n",
    "\n",
    "    # gets the sum of all values in the matrix\n",
    "    n = confusion_matrix_v.sum()\n",
    "\n",
    "    # gets the rows, cols\n",
    "    r, k = confusion_matrix_v.shape\n",
    "\n",
    "    # gets the chi-squared\n",
    "    chi2 = chi2_contingency(confusion_matrix_v)[0]\n",
    "\n",
    "    # makes the bias correction\n",
    "    chi2corr = max(0, chi2 - (k-1) * (r-1) / (n-1))\n",
    "    kcorr = k - (k-1) ** 2 / (n-1)\n",
    "    rcorr = r - (r-1) ** 2 / (n-1)\n",
    "\n",
    "    # returns cramér V\n",
    "    return np.sqrt((chi2corr/n) / min(kcorr-1, rcorr-1))\n",
    "\n",
    "def model_selection(X,y):\n",
    "    \n",
    "    # Modelos\n",
    "    models = [('lr',LogisticRegression()),\n",
    "              ('knn',KNeighborsClassifier()),\n",
    "              ('svm',SVC()),\n",
    "              ('dt',DecisionTreeClassifier()),\n",
    "              ('rf', RandomForestClassifier()),\n",
    "              ('lgb',lgb.LGBMClassifier()),\n",
    "              ('xgboost', XGBClassifier())]\n",
    "\n",
    "    # Resultados\n",
    "    resultados = {'LR': [],\n",
    "                  'KNN': [],\n",
    "                  'SVM': [],\n",
    "                  'DecisionTree': [],\n",
    "                  'RandomForestClassifier': [],\n",
    "                  'LGBM': [],\n",
    "                  'XGBOOST': []}\n",
    "\n",
    "    # Testando algoritmos\n",
    "    for name, model in models:\n",
    "        \n",
    "\n",
    "        # cross-validação\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        \n",
    "        # resultado\n",
    "        resultado = cross_val_score(estimator=model,\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    scoring='f1',\n",
    "                                    cv=cv,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        if name == 'lr':\n",
    "            resultados['LR'].append(np.mean(resultado))\n",
    "        elif name == 'knn':\n",
    "            resultados['KNN'].append(np.mean(resultado)) \n",
    "        elif name == 'svm':\n",
    "            resultados['SVM'].append(np.mean(resultado))\n",
    "        elif name == 'dt':\n",
    "            resultados['DecisionTree'].append(np.mean(resultado))\n",
    "        elif name == 'rf':\n",
    "            resultados['RandomForestClassifier'].append(np.mean(resultado))\n",
    "        elif name == 'lgb':\n",
    "            resultados['LGBM'].append(np.mean(resultado))\n",
    "        elif name == 'xgboost':\n",
    "            resultados['XGBOOST'].append(np.mean(resultado))\n",
    "\n",
    "    # Painel\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Colection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:08:57.652174Z",
     "start_time": "2020-11-28T13:08:57.620058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv('data/churn.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T22:13:32.782942Z",
     "start_time": "2020-11-19T22:13:32.779777Z"
    },
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Book de Variáveis:**\n",
    "\n",
    "Age: Idade do cliente.\n",
    "\n",
    "Balance: Quantidade de dinheiro na\n",
    "\n",
    "CreditScore: Score de crédito do cliente.\n",
    "\n",
    "CustomerId: Identificador unico do cliente.\n",
    "\n",
    "EstimatedSalary: Salário estimado do cliente.\n",
    "\n",
    "Exited: Variável target se ocorreu ou não churn do cliente.\n",
    "\n",
    "Gender: Genêro do cliente.\n",
    "\n",
    "Geography: Localizaçao do cliente.\n",
    "\n",
    "HasCrCard: Flag se o cliente possui um cartão de crédito ou não\n",
    "\n",
    "IsActiveMember: Flag se o cliente é ativo ou não.\n",
    "\n",
    "RowNumber: Número da linha no dataset.\n",
    "\n",
    "Surname: Sobrenome do cliente.\n",
    "\n",
    "Ternure: Quantidade em anos que o cliente ainda está no banco ( no-churn ) e ela também diz quanto tempo o cliente ficou no banco até o churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:00.819799Z",
     "start_time": "2020-11-28T13:09:00.749470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Describe\n",
    "pd.DataFrame({'missing' :churn.isna().mean(),\n",
    "              'uniques' :churn.nunique(),\n",
    "              'dtypes'  :churn.dtypes,\n",
    "              'min'     :churn.min(),\n",
    "              'mean'    :churn.mean(),\n",
    "              'median'  :churn.median(),\n",
    "              'max'     :churn.max(),\n",
    "              'skew'    :churn.skew(),\n",
    "              'kurtosis':churn.kurtosis()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " - Temos dados de diferentes escalas\n",
    " - 'Customerid' e 'RowNumber' é um idientificador único podemos eliminar ou utiliza-lo como index do dataframe.\n",
    " - As variáveis 'HasCrCard' 'IsActiveMember' são categoricas ordinais iremos alterar o seu tipo para category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Target - Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:01.668775Z",
     "start_time": "2020-11-28T13:09:01.541130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checkando o balanciamento da variável Target\n",
    "ax = sns.countplot(x='Exited', hue=None, data=churn)\n",
    "ax.figure.set_size_inches(10, 6)\n",
    "ax.set_title('Feature Distribution', fontsize=18, loc='center')\n",
    "ax.set_xlabel('Exited', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax=ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Podemos observar que as classes da variável Target esta desbalanciada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Descrever Gender vs Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:02.288009Z",
     "start_time": "2020-11-28T13:09:02.153232Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='Gender', hue='Exited', data=churn)\n",
    "ax.figure.set_size_inches(10, 6)\n",
    "ax.set_title('Feature Distribution', fontsize=18, loc='center')\n",
    "ax.set_xlabel('Gender', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax=ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " - Aparentemente não existe uma concentração do evento de 'Churn' conforme o genero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Descrever Geography vs Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:02.904934Z",
     "start_time": "2020-11-28T13:09:02.747687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='Geography', hue='Exited', data=churn)\n",
    "ax.figure.set_size_inches(10, 6)\n",
    "ax.set_title('Feature Distribution', fontsize=18, loc='center')\n",
    "ax.set_xlabel('Geography', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax=ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:03.515220Z",
     "start_time": "2020-11-28T13:09:03.502645Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Percentual de observações por valores Geography\n",
    "churn.groupby('Geography').count()['RowNumber'].apply(lambda x: (x/churn.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Notamos que proporcionalmente parece ocorrer um maior churn de clientes da Alemanha. A mesma possui comente 25% das observações porém possui mais eventos churn que as demais categorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Descrever HasCrCard vs Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:06.326162Z",
     "start_time": "2020-11-28T13:09:06.196368Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='HasCrCard', hue='Exited', data=churn)\n",
    "ax.figure.set_size_inches(10, 6)\n",
    "ax.set_title('Feature Distribution', fontsize=18, loc='center')\n",
    "ax.set_xlabel('HasCrCard', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax=ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:06.442201Z",
     "start_time": "2020-11-28T13:09:06.431559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Percentual de observações por valores HasCrCard\n",
    "churn.groupby('HasCrCard').count()['RowNumber'].apply(lambda x: (x/churn.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T23:40:48.865585Z",
     "start_time": "2020-11-19T23:40:48.859144Z"
    },
    "hidden": true
   },
   "source": [
    "- Devido a maior concentração de obseravções com cartão de credito temos também maior numero de eventos de churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Descrever IsActiveMember vs Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:09.156319Z",
     "start_time": "2020-11-28T13:09:09.030295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='IsActiveMember', hue='Exited', data=churn)\n",
    "ax.figure.set_size_inches(10, 6)\n",
    "ax.set_title('Feature Distribution', fontsize=18, loc='center')\n",
    "ax.set_xlabel('IsActiveMember', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax=ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:09.279271Z",
     "start_time": "2020-11-28T13:09:09.268890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Percentual de observações por valores HasCrCard\n",
    "churn.groupby('IsActiveMember').count()['RowNumber'].apply(lambda x: (x/churn.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T23:38:49.919536Z",
     "start_time": "2020-11-19T23:38:49.914461Z"
    },
    "hidden": true
   },
   "source": [
    " - Em um primeiro momento notamos que a inatividade leva a um maior churn. Os eventos estão distribuídos porém com maior quantidade de eventos de churn na categoria de inatividade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T00:11:51.737992Z",
     "start_time": "2020-11-20T00:11:51.734725Z"
    },
    "hidden": true
   },
   "source": [
    "## Alterando os tipos das variáveis 'HasCrCard', 'IsActiveMember', Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:11.652693Z",
     "start_time": "2020-11-28T13:09:11.636393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Alterando o tipo de dados para category\n",
    "colunas = ['HasCrCard','IsActiveMember', 'Exited', 'Surname', 'Geography','Gender']\n",
    "\n",
    "for col in colunas:\n",
    "    churn[col] = churn[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:11.853124Z",
     "start_time": "2020-11-28T13:09:11.847445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# checkando os tipos\n",
    "churn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Checkando a Presença de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:15.406998Z",
     "start_time": "2020-11-28T13:09:14.770157Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Variáveis\n",
    "variables = churn.select_dtypes(['int64', 'float64']).columns.to_list()\n",
    "\n",
    "# Setando a posicão inicial\n",
    "n = 1\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for column in churn[variables].columns:\n",
    "    plt.subplot(4, 4, n)\n",
    "    _ = sns.boxplot(x=column, data=churn)\n",
    "    n += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " - Observamos Outliers nas variáveis 'CreditScore', 'Age','NumOfProducts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### CreditScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:18.320885Z",
     "start_time": "2020-11-28T13:09:18.312499Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculando o Q1 e Q3 e IQR\n",
    "Q1 = np.quantile(churn['CreditScore'], .25)\n",
    "Q3 = np.quantile(churn['CreditScore'], .75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculando os limites low and high\n",
    "low = Q1 - 1.5 * IQR\n",
    "high = Q3 + 1.5 * IQR\n",
    "\n",
    "# priting the limits\n",
    "print(f'O limite inferior é {low}')\n",
    "print(f'O limite superior é {high}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " - Filtrando somente o limite inferior, pois no boxplot observamos outliers somente no limite inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:18.938736Z",
     "start_time": "2020-11-28T13:09:18.929926Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculando o Q1 e Q3 e IQR\n",
    "Q1 = np.quantile(churn['Age'], .25)\n",
    "Q3 = np.quantile(churn['Age'], .75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculando os limites low and high\n",
    "low = Q1 - 1.5 * IQR\n",
    "high = Q3 + 1.5 * IQR\n",
    "\n",
    "# priting the limits\n",
    "print(f'O limite inferior é {low}')\n",
    "print(f'O limite superior é {high}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T09:39:14.619098Z",
     "start_time": "2020-11-21T09:39:14.613208Z"
    },
    "hidden": true
   },
   "source": [
    " - Filtrando somente o limite superior, pois no boxplot observamos outliers somente no limite superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NumOfProducts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Iremos filtrar todas as observações com 4 produtos, pois conforme o boxplot os outliers estão nesse patamar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Limpeza de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Cleaning Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:30.337736Z",
     "start_time": "2020-11-28T13:09:30.321466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtrando 'CreditScore' somente o limite inferior.\n",
    "churn = churn.loc[churn['CreditScore']>400, ]\n",
    "\n",
    "# Filtrando 'Age' somente o limite inferior\n",
    "churn = churn.loc[churn['Age']<59, ]\n",
    "\n",
    "# Filtrando 'NumOfProducts'\n",
    "churn = churn.loc[churn['NumOfProducts']<4, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:30.988588Z",
     "start_time": "2020-11-28T13:09:30.394826Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking the outliers again.\n",
    "# Variáveis\n",
    "variables = churn.select_dtypes(['int64', 'float64']).columns.to_list()\n",
    "\n",
    "# Setando a posicão inicial\n",
    "n = 1\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for column in churn[variables].columns:\n",
    "    plt.subplot(4, 4, n)\n",
    "    _ = sns.boxplot(x=column, data=churn)\n",
    "    n += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminar as variáveis RowNumber, CustomersId, Surname(granularidade alta) por apresentarem pouco ganho de informação para a modelagem do nosso problema.\n",
    "- Criar variável com Kmeans usando k=2. O valor de k é devido a estarmos trabalhando com um problema binário.\n",
    "- Criar variável EstimatedSalary por location. Distribuição da renda podem nos ajudar na modelagem do problema.\n",
    "- Binning as variáveis CreditScore, Age, Tenure, Balance, EstimatedSalary. Realizando o Binning dessas variáveis diminuimos a granularidade das mesmas o que irá facilitar a modelagem do problema futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:34.492168Z",
     "start_time": "2020-11-28T13:09:34.487555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copia do dataset original\n",
    "dataset = churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:34.822139Z",
     "start_time": "2020-11-28T13:09:34.818518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eliminando RowNumber, CustomersId, Surname(granularidade alta)\n",
    "dataset.drop(['RowNumber','CustomerId','Surname'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:35.898698Z",
     "start_time": "2020-11-28T13:09:35.087351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variável kmeans distancia eucliadiana\n",
    "# Criando copia\n",
    "churn_temp = dataset.copy()\n",
    "\n",
    "# Encoder\n",
    "enc = OrdinalEncoder()\n",
    "churn_temp['Gender'] = churn_temp['Gender'].apply(lambda x: 1 if x == 'Female' else 0)\n",
    "churn_temp['Geography'] = enc.fit_transform(np.array(churn_temp['Geography']).reshape(-1,1))\n",
    "\n",
    "# kmeans model\n",
    "model = KMeans(n_clusters=2,init='k-means++')\n",
    "model.fit(churn_temp)\n",
    "dataset['kmeans_group'] = model.labels_\n",
    "dataset['kmeans_group'] = dataset['kmeans_group'].astype('category')\n",
    "dataset['kmeans_group'] = dataset['kmeans_group'].apply(lambda x: 'G1' if x==1 else 'G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:36.222038Z",
     "start_time": "2020-11-28T13:09:36.204210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criar variável Balance por location\n",
    "group_balance = dataset.groupby('Geography').agg({'Balance': ['mean']}).reset_index()\n",
    "group = pd.concat([group_balance['Geography'],group_balance['Balance']['mean']], axis=1)\n",
    "dataset = dataset.merge(group, left_on='Geography', right_on='Geography', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:36.582064Z",
     "start_time": "2020-11-28T13:09:36.565252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criar variável EstimatedSalary por location\n",
    "group_balance = dataset.groupby('Geography').agg({'EstimatedSalary': ['mean']}).reset_index()\n",
    "group = pd.concat([group_balance['Geography'],  group_balance['EstimatedSalary']['mean']], axis=1)\n",
    "dataset = dataset.merge(group, left_on='Geography', right_on='Geography', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:37.961760Z",
     "start_time": "2020-11-28T13:09:37.938619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binning\n",
    "# CreditScore\n",
    "dataset['CreditScore_new'] = pd.qcut(dataset['CreditScore'],q=10, labels=['G1','G2','G3','G4','G5','G6','G7','G8','G9','G10'])\n",
    "\n",
    "# Age\n",
    "dataset['Age_new'] = pd.qcut(dataset['Age'],q=10, labels=['G1','G2','G3','G4','G5','G6','G7','G8','G9','G10'])\n",
    "\n",
    "# Tenure\n",
    "dataset['Tenure_new'] = pd.qcut(dataset['Tenure'],q=10, labels=['G1','G2','G3','G4','G5','G6','G7','G8','G9','G10'])\n",
    "\n",
    "# Balance\n",
    "dataset['Balance_new'] = pd.qcut(dataset['Balance'],q=[.35, .70, 1], labels = ['G1','G2'])\n",
    "\n",
    "# EstimatedSalary\n",
    "dataset['EstimatedSalary_new'] = pd.qcut(dataset['EstimatedSalary'],q=10, labels=['G1','G2','G3','G4','G5','G6','G7','G8','G9','G10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:38.399495Z",
     "start_time": "2020-11-28T13:09:38.395886Z"
    }
   },
   "outputs": [],
   "source": [
    "# LTV\n",
    "balance = dataset['Balance'].astype('int64')\n",
    "dataset['LTV'] = balance / (dataset['Tenure'] + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:38.963585Z",
     "start_time": "2020-11-28T13:09:38.938053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>kmeans_group</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>CreditScore_new</th>\n",
       "      <th>Age_new</th>\n",
       "      <th>Tenure_new</th>\n",
       "      <th>Balance_new</th>\n",
       "      <th>EstimatedSalary_new</th>\n",
       "      <th>LTV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>G2</td>\n",
       "      <td>62092.636516</td>\n",
       "      <td>99899.180814</td>\n",
       "      <td>G4</td>\n",
       "      <td>G7</td>\n",
       "      <td>G2</td>\n",
       "      <td>G1</td>\n",
       "      <td>G6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>G1</td>\n",
       "      <td>62092.636516</td>\n",
       "      <td>99899.180814</td>\n",
       "      <td>G1</td>\n",
       "      <td>G7</td>\n",
       "      <td>G8</td>\n",
       "      <td>G2</td>\n",
       "      <td>G6</td>\n",
       "      <td>19711.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>G2</td>\n",
       "      <td>62092.636516</td>\n",
       "      <td>99899.180814</td>\n",
       "      <td>G7</td>\n",
       "      <td>G6</td>\n",
       "      <td>G1</td>\n",
       "      <td>G1</td>\n",
       "      <td>G5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>G2</td>\n",
       "      <td>62092.636516</td>\n",
       "      <td>99899.180814</td>\n",
       "      <td>G10</td>\n",
       "      <td>G9</td>\n",
       "      <td>G7</td>\n",
       "      <td>G1</td>\n",
       "      <td>G1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>G1</td>\n",
       "      <td>62092.636516</td>\n",
       "      <td>99899.180814</td>\n",
       "      <td>G1</td>\n",
       "      <td>G8</td>\n",
       "      <td>G4</td>\n",
       "      <td>G2</td>\n",
       "      <td>G4</td>\n",
       "      <td>34646.585366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          502    France  Female   42       8  159660.80              3   \n",
       "2          699    France  Female   39       1       0.00              2   \n",
       "3          822    France    Male   50       7       0.00              2   \n",
       "4          501    France    Male   44       4  142051.07              2   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited kmeans_group  \\\n",
       "0          1               1        101348.88       1           G2   \n",
       "1          1               0        113931.57       1           G1   \n",
       "2          0               0         93826.63       0           G2   \n",
       "3          1               1         10062.80       0           G2   \n",
       "4          0               1         74940.50       0           G1   \n",
       "\n",
       "         mean_x        mean_y CreditScore_new Age_new Tenure_new Balance_new  \\\n",
       "0  62092.636516  99899.180814              G4      G7         G2          G1   \n",
       "1  62092.636516  99899.180814              G1      G7         G8          G2   \n",
       "2  62092.636516  99899.180814              G7      G6         G1          G1   \n",
       "3  62092.636516  99899.180814             G10      G9         G7          G1   \n",
       "4  62092.636516  99899.180814              G1      G8         G4          G2   \n",
       "\n",
       "  EstimatedSalary_new           LTV  \n",
       "0                  G6      0.000000  \n",
       "1                  G6  19711.111111  \n",
       "2                  G5      0.000000  \n",
       "3                  G1      0.000000  \n",
       "4                  G4  34646.585366  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dando uma olhada como ficou o dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:46.456690Z",
     "start_time": "2020-11-28T13:09:44.258218Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking the outliers again.\n",
    "# Variáveis\n",
    "variables = dataset.select_dtypes(['category']).columns.to_list()\n",
    "\n",
    "# Setando a posicão inicial\n",
    "n = 1\n",
    "\n",
    "plt.figure(figsize=(36, 32))\n",
    "for column in dataset[variables].columns:\n",
    "    plt.subplot(4, 4, n)\n",
    "    _ = sns.countplot(y=column,hue='Exited', data=dataset)\n",
    "    n += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6,wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Os casos de churn paracem diminuir a medida que aumenta a variável 'Ternure'\n",
    "- Os casos de churn parecem aumentar a medida que a idade dos clientes também aumenta.\n",
    "- Outro ponto parece haver um maior concetração de churn entre os clientes que não estão ativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:53.511371Z",
     "start_time": "2020-11-28T13:09:51.371701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Antes do feature eng\n",
    "variables = dataset.select_dtypes(['int64','float64']).columns.to_list()\n",
    "#variables.remove('RowNumber'), variables.remove('CustomerId')\n",
    "\n",
    "# Setando a posicão inicial\n",
    "n = 1\n",
    "\n",
    "plt.figure(figsize=(36, 32))\n",
    "for column in dataset[variables].columns[:len(variables)-1]:\n",
    "    plt.subplot(4, 4, n)\n",
    "    _ = sns.histplot(data = dataset, x=column, hue='Exited')\n",
    "    n += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6,wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T23:33:46.999508Z",
     "start_time": "2020-11-23T23:33:46.994799Z"
    }
   },
   "source": [
    "- Confirmamos a tendência de maior churn entre clientes com maior idade.\n",
    "- Observamos também muitos clientes com 'balance' igual a zero, porém seme uma concetração atipica de casos de churn\n",
    "- Distribuições proximas da normal com um skew fraco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:09:57.963965Z",
     "start_time": "2020-11-28T13:09:57.464108Z"
    }
   },
   "outputs": [],
   "source": [
    "# LTV\n",
    "LTV = dataset.loc[(dataset['LTV'] != 0) & (dataset['LTV'] < (0.3*1000000)),]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.histplot(data = LTV, x='LTV', hue='Exited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuição com forte skew. Iremos proceder com normalização dos dados na etapa de Feature Eng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:10:50.182440Z",
     "start_time": "2020-11-28T13:10:09.970803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variáveis\n",
    "variables = dataset.select_dtypes(['int64','float64']).columns.to_list()\n",
    "variables.append('Exited')\n",
    "\n",
    "sns.pairplot(dataset[variables], hue='Exited')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Não é possível observar nenhuma relação linear entre as variáveis.\n",
    "- É possivel também notar uma concentração de casos de churn no NumOfProducts igual a 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variáveis Numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:18:46.475962Z",
     "start_time": "2020-11-28T13:18:46.048643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pearson correlation Matrix\n",
    "Myheat_map(dataset =dataset, variaveis=variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observamos uma grande correlação entre a variavel mean_Y e mean_X iremos excluir uma delas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:18:50.886213Z",
     "start_time": "2020-11-28T13:18:50.482496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removendo a variável mean_x\n",
    "variables.remove('mean_x')\n",
    "Myheat_map(dataset =dataset, variaveis=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:18:54.297425Z",
     "start_time": "2020-11-28T13:18:54.056980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numericas com relação a target\n",
    "variables = dataset.select_dtypes(['int64','float64']).columns.to_list()\n",
    "\n",
    "# Correlações\n",
    "corrs = [pointbiserialr(dataset['Exited'], dataset[var])[0] for var in variables]\n",
    "df_corr = pd.DataFrame({'Exited': corrs}, index=variables)\n",
    "\n",
    "# Plot Matrix\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(df_corr, annot=True, annot_kws={\"fontsize\":14}, cmap='viridis')\n",
    "plt.title(\"Pointbiserialr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nenhuma variável com a correlação significante  com relação a variávl Target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis categoricas - cramers v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:21:55.478014Z",
     "start_time": "2020-11-28T13:21:53.688639Z"
    }
   },
   "outputs": [],
   "source": [
    "# colunas\n",
    "cols = dataset.select_dtypes(['category', 'object']).columns.to_list()\n",
    "\n",
    "# Dicionário para registro das correlações\n",
    "dictt = {\n",
    "        'Geography': [],\n",
    "        'Gender': [],\n",
    "        'HasCrCard': [],\n",
    "        'IsActiveMember': [],\n",
    "        'Exited': [],\n",
    "        'kmeans_group': [],\n",
    "        'CreditScore_new': [],\n",
    "        'Age_new': [],\n",
    "        'Tenure_new': [],\n",
    "        'Balance_new': [],\n",
    "        'EstimatedSalary_new': [],\n",
    "        'Exited': []\n",
    "        }\n",
    "\n",
    "for col in cols:\n",
    "    for col1 in cols:\n",
    "        corr = cramer_v(dataset[col], dataset[col1])\n",
    "        dictt[col].append(corr)\n",
    "        \n",
    "# Matriz de Correlação\n",
    "df_cramer1 = pd.DataFrame(dictt)\n",
    "df_cramer1 = df_cramer1.set_index(df_cramer1.columns)\n",
    "\n",
    "# HeatMap\n",
    "fig, ax = plt.subplots()\n",
    "ax.figure.set_size_inches(16, 6)\n",
    "\n",
    "mask = np.triu(np.ones_like(df_cramer1, dtype=np.bool))\n",
    "sns.heatmap(df_cramer1, mask=mask, linewidths=.5, annot=True, annot_kws={\"fontsize\":14}, cmap='viridis')\n",
    "plt.title(\"Cramér V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Não encontramos nenhuma variável com alta correlação. Estou considerando correlações acima de 0.6 seriam eliminadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Teste de Hipoteses - **Não Feito**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:23:04.258452Z",
     "start_time": "2020-11-28T13:23:04.245915Z"
    }
   },
   "outputs": [],
   "source": [
    "# X e y\n",
    "X = dataset.drop('Exited', axis=1)\n",
    "y = dataset['Exited']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=1)\n",
    "\n",
    "# Alterando os tipos da Geography e Gender\n",
    "varr = ['Geography', 'Gender']\n",
    "for var in varr:\n",
    "    Xtrain[var] = Xtrain[var].astype('category')\n",
    "    Xtest[var] = Xtest[var].astype('category')\n",
    "\n",
    "# Alterando o tipo dos ys\n",
    "ytrain = ytrain.astype('int64')\n",
    "ytest = ytest.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:23:16.787994Z",
     "start_time": "2020-11-28T13:23:16.588741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ordinal Encoder\n",
    "variaveis = ['Geography', \n",
    "             'Gender',\n",
    "             'kmeans_group',\n",
    "             'CreditScore_new', \t\n",
    "             'Age_new', \t\n",
    "             'Tenure_new', \t\n",
    "             'Balance_new', \t\n",
    "             'EstimatedSalary_new']\n",
    "\n",
    "# Instanciando o Ordinal Encoder\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "for var in variaveis:\n",
    "    Xtrain[var] = enc.fit_transform(np.array(Xtrain[var]).reshape(-1,1))\n",
    "    Xtest[var] = enc.fit_transform(np.array(Xtest[var]).reshape(-1,1))\n",
    "\n",
    "# RobustScaler\n",
    "variaveis = ['CreditScore', \n",
    "             'Age', \n",
    "             'Tenure', \n",
    "             'Balance', \n",
    "             'NumOfProducts', \n",
    "             'EstimatedSalary', \n",
    "             'mean_x', \n",
    "             'mean_y',\n",
    "             'LTV']\n",
    "\n",
    "# Instanciando o Robust Scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "for var in variaveis:\n",
    "    Xtrain[var] = scaler.fit_transform(np.array(Xtrain[var]).reshape(-1,1))\n",
    "    Xtest[var] = scaler.fit_transform(np.array(Xtest[var]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanciamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:23:21.274692Z",
     "start_time": "2020-11-28T13:23:20.751531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adicionando balanciamento de dados ao Pipeline\n",
    "\n",
    "# Instanciando o balanciador\n",
    "smt = SMOTETomek(sampling_strategy='minority' ,random_state=42)\n",
    "Xtrain_smt, ytrain_smt = smt.fit_resample(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T13:23:22.390795Z",
     "start_time": "2020-11-28T13:23:22.283974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Exited', ylabel='count'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Exited', data=pd.DataFrame(ytrain_smt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T14:24:20.128209Z",
     "start_time": "2020-11-28T14:24:06.931074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 attributes confirmed important: ['IsActiveMember', 'Geography', 'EstimatedSalary_new', 'Age', 'mean_x', 'Gender', 'kmeans_group', 'Age_new', 'NumOfProducts', 'Balance_new', 'CreditScore', 'Balance']\n",
      "1 attributes confirmed unimportant: ['EstimatedSalary']\n",
      "6 tentative attributes remains: ['HasCrCard', 'mean_y', 'Tenure_new', 'Tenure', 'LTV', 'CreditScore_new']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "#Selecionador de Features\n",
    "Feature_Selector = BorutaShap(model=model,\n",
    "                              importance_measure='shap',\n",
    "                              classification=True, )\n",
    "\n",
    "Feature_Selector.fit(X=Xtrain_smt,y=ytrain_smt, n_trials=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T14:24:21.344879Z",
     "start_time": "2020-11-28T14:24:21.333743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>Geography</th>\n",
       "      <th>EstimatedSalary_new</th>\n",
       "      <th>Age</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>Gender</th>\n",
       "      <th>kmeans_group</th>\n",
       "      <th>Age_new</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>Balance_new</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253731</td>\n",
       "      <td>-0.758829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.455224</td>\n",
       "      <td>0.274326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.343284</td>\n",
       "      <td>-0.298862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.089552</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>-0.299031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsActiveMember  Geography  EstimatedSalary_new       Age  mean_x  Gender  \\\n",
       "0               0        0.0                  6.0  0.416667     0.0     0.0   \n",
       "1               0        0.0                  6.0 -0.333333     0.0     1.0   \n",
       "2               1        0.0                  4.0 -0.500000     0.0     1.0   \n",
       "3               0        0.0                  2.0  1.916667     0.0     0.0   \n",
       "4               1        1.0                  1.0 -0.166667     1.0     1.0   \n",
       "\n",
       "   kmeans_group  Age_new  NumOfProducts  Balance_new  CreditScore   Balance  \n",
       "0           1.0      7.0            3.0          0.0    -0.253731 -0.758829  \n",
       "1           0.0      3.0            0.0          1.0    -0.455224  0.274326  \n",
       "2           1.0      2.0            1.0          0.0    -1.343284 -0.298862  \n",
       "3           0.0      1.0            0.0          0.0     1.089552  0.001389  \n",
       "4           1.0      4.0            0.0          0.0     0.059701 -0.299031  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as variáveis selecioandas\n",
    "X_subset = Feature_Selector.Subset()\n",
    "X_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando as a performance dos modelos, utilizando todas as variáveis contra utilizando somente as variáveis selecionadas. Podemos observar que somente a Lightgbm obteve uma leve melhora com as variáveis selecionadas quanto os demais tiveram uma leve queda em seus f1 scores.\n",
    "\n",
    "**--Vamos seguir com o modelo LGBM--**\n",
    "\n",
    "A métrica base utilizada será o f1-score em conjunto com recall. A principal razão é por estarmos trabalhando com um problema de binário cujo o evento alvo é raro, dessa forma, queremos ter alta capacidade de detecção do evento alvo (recall) sem incorrer um muitos erros de previsão da classe negativa(F1 score nos ajuda nessa parte).\n",
    "\n",
    "Lembrando\n",
    "F1 score é média harmonica da recall e da precision.\n",
    "Recall é a taxa de detecção de uma determinada classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Com todas as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T14:28:01.344835Z",
     "start_time": "2020-11-28T14:27:52.988832Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750809</td>\n",
       "      <td>0.844769</td>\n",
       "      <td>0.760728</td>\n",
       "      <td>0.862271</td>\n",
       "      <td>0.918109</td>\n",
       "      <td>0.910873</td>\n",
       "      <td>0.909518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LR       KNN       SVM  DecisionTree  RandomForestClassifier  \\\n",
       "0  0.750809  0.844769  0.760728      0.862271                0.918109   \n",
       "\n",
       "       LGBM   XGBOOST  \n",
       "0  0.910873  0.909518  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selicionando o modelo a ser trabalhado.\n",
    "model_selection(Xtrain_smt, ytrain_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Com as variáveis selecionadas pelo Boruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T14:28:15.209003Z",
     "start_time": "2020-11-28T14:28:09.179912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748646</td>\n",
       "      <td>0.842228</td>\n",
       "      <td>0.767796</td>\n",
       "      <td>0.862308</td>\n",
       "      <td>0.90752</td>\n",
       "      <td>0.909133</td>\n",
       "      <td>0.908933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LR       KNN       SVM  DecisionTree  RandomForestClassifier  \\\n",
       "0  0.748646  0.842228  0.767796      0.862308                 0.90752   \n",
       "\n",
       "       LGBM   XGBOOST  \n",
       "0  0.909133  0.908933  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando o modelo a ser trabalhado\n",
    "model_selection(X_subset, ytrain_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning/Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo escolhido foi a LGBM, abaixo um breve resumo.\n",
    "\n",
    "** LGBM: **\n",
    "\n",
    "O que é LGBM?\n",
    "\n",
    "De acordo com a documentação adequada do LightGBM, é uma estrutura de aumento de gradiente que usa algoritmos de aprendizagem baseados em árvore. Ele é projetado para ser distribuído e eficiente com as seguintes vantagens:\n",
    "\n",
    "- Maior velocidade de treinamento e maior eficiência.\n",
    "\n",
    "- Menor uso de memória.\n",
    "\n",
    "- Melhor precisão.\n",
    "\n",
    "- Suporte para aprendizagem paralela e GPU.\n",
    "\n",
    "- Capaz de lidar com dados em grande escala.\n",
    "\n",
    "A principal diferença do LightGBM em comparação com outros algoritmos baseados em árvore é que ele faz a árvore crescer de forma vertical (folha) em vez de horizontal (nível). Ele escolherá a folha com perda máxima de delta para crescer e continuar crescendo a mesma folha; normalmente, um algoritmo Leaf-wise pode reduzir mais perdas do que um algoritmo-wise.\n",
    "\n",
    "Os diagramas abaixo podem fornecer uma compreensão mais visual:\n",
    "\n",
    "Restrições: Normalmente, o LightGBM não funciona bem em pequenos conjuntos de dados, não há limite formal aqui, mas 10.000 instâncias seria um bom número.\n",
    "\n",
    "Parâmetros principais:\n",
    "\n",
    "profundidade máxima,\n",
    "boosting_type,\n",
    "taxa de Aprendizagem,\n",
    "n_estimators,\n",
    "num_leaves,\n",
    "subamostra,\n",
    "min_split_gain,\n",
    "min_split_weight,\n",
    "min_child_samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training LGBM\n",
    "\n",
    "def train_lightGBM(X, y, n_iter, n_splits=10):\n",
    "    \n",
    "    # Transformador de Colunas\n",
    "    ct = ColumnTransformer([(\"ordinal\", OrdinalEncoder(), ['Geography','Gender','CreditScore_new', 'Age_new', 'Tenure_new', 'Balance_new','EstimatedSalary_new']),\n",
    "                        (\"scaler\", RobustScaler(), ['CreditScore','Age','Tenure','Balance', 'NumOfProducts','EstimatedSalary','mean_y', 'LTV'])],remainder='passthrough')\n",
    "    \n",
    "    # Instanciando o balanciador\n",
    "    smt = SMOTETomek(sampling_strategy='minority' ,random_state=42)\n",
    "    \n",
    "    # Preprocessing e modelo\n",
    "    model = Pipeline([('ct',ct),\n",
    "                      ('smt', smt),\n",
    "                      ('model', lgb.LGBMClassifier())])\n",
    "    \n",
    "\n",
    "    # Dicionário de metricas\n",
    "    resultados = {'ACC_MEAN': [],\n",
    "                  'ACC_STD': [],\n",
    "                  'KAPPA_MEAN': [],\n",
    "                  'KAPPA_STD': [],\n",
    "                  'RECALL_MEAN': [],\n",
    "                  'RECALL_STD': [],\n",
    "                  'F1_MEAN': [],\n",
    "                  'F1_STD': [],\n",
    "                  'PRECISION_MEAN': [],\n",
    "                  'PRECISION_STD': [] }\n",
    "    \n",
    "    # cross-validiação\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    # resultado\n",
    "    acc = []\n",
    "    kappa = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    precision = []\n",
    "    for linhas_treino, linhas_valid in skf.split(X, y):\n",
    "\n",
    "        X_treino, X_valid = X.iloc[linhas_treino], X.iloc[linhas_valid]\n",
    "        y_treino, y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]\n",
    "\n",
    "        model.fit(X_treino, y_treino)\n",
    "        pred = model.predict(X_valid)\n",
    "        Acc = accuracy_score(y_valid, pred)\n",
    "        Kappa =  cohen_kappa_score(y_valid, pred)\n",
    "        Recall = recall_score(y_valid, pred)\n",
    "        F1 = f1_score(y_valid, pred)\n",
    "        Precision = precision_score(y_valid, pred)\n",
    "        acc.append(Acc)\n",
    "        kappa.append(Kappa)\n",
    "        recall.append(Recall)\n",
    "        f1.append(F1)\n",
    "        precision.append(Precision)\n",
    "        \n",
    "    # Treinando o modelo em todos os dados\n",
    "    model = model.fit(X,y)\n",
    "    \n",
    "    # Salvando o modelo em pickle\n",
    "    with open('models/modelo_base.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "    resultados['ACC_MEAN'].append(np.mean(acc))\n",
    "    resultados['ACC_STD'].append(np.std(acc))\n",
    "    resultados['KAPPA_MEAN'].append(np.mean(kappa))\n",
    "    resultados['KAPPA_STD'].append(np.std(kappa))\n",
    "    resultados['RECALL_MEAN'].append(np.mean(recall))\n",
    "    resultados['RECALL_STD'].append(np.std(recall))\n",
    "    resultados['F1_MEAN'].append(np.mean(f1))\n",
    "    resultados['F1_STD'].append(np.std(f1))\n",
    "    resultados['PRECISION_MEAN'].append(np.mean(precision))\n",
    "    resultados['PRECISION_STD'].append(np.std(precision))\n",
    "    \n",
    "    print('####### Bussines Metrics #######')\n",
    "    \n",
    "    # Painel\n",
    "    painel_df = pd.DataFrame(resultados).T\n",
    "    return painel_df, model\n",
    "\n",
    "painel, modelo_base = train_lightGBM(X=Xtrain, y=ytrain, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painel de metricas do modelo baseline(sem Tunning)\n",
    "painel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid de Parametros\n",
    "param_grid = {\n",
    "              'learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "              'n_estimators': [100, 250, 500],\n",
    "              'num_leaves': [10, 15, 31, 45],\n",
    "              'min_child_samples' : [5,10,20]\n",
    "             }\n",
    "\n",
    "# cross-validiação\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "def tunnig_gridsearch(Xtrain, ytrain, model, param_grid, cv, scoring, refit):\n",
    "    \n",
    "#     # Transformador de Colunas\n",
    "#     ct = ColumnTransformer([(\"ordinal\", OrdinalEncoder(), ['Geography','Gender','CreditScore_new', 'Age_new', 'Tenure_new', 'Balance_new','EstimatedSalary_new']),\n",
    "#                         (\"scaler\", RobustScaler(), ['CreditScore','Age','Tenure','Balance', 'NumOfProducts','EstimatedSalary','mean_y', 'LTV'])],remainder='passthrough')\n",
    "    \n",
    "#     # Preprocessing e modelo\n",
    "#     prep_pipeline = Pipeline([('ct',ct),('smt', smt)])\n",
    "                         \n",
    "#     X = pd.DataFrame(prep_pipeline.fit_resample(Xtrain, ytrain)[0], columns=Xtrain.columns)\n",
    "#     y = pd.DataFrame(prep_pipeline.fit_resample(Xtrain, ytrain)[1])\n",
    "    \n",
    "    search = GridSearchCV(estimator=model.named_steps['model'],\n",
    "                          param_grid=param_grid,\n",
    "                          scoring=scoring,\n",
    "                          refit=refit,\n",
    "                          cv=cv,\n",
    "                          verbose=1,\n",
    "                          n_jobs=-1)\n",
    "    \n",
    "    search.fit(Xtrain, ytrain)\n",
    "    \n",
    "    return search.best_params_, search.cv_results_\n",
    "\n",
    "# Tunning\n",
    "best_params, cv_results = tunnig_gridsearch(Xtrain=Xtrain,\n",
    "                                             ytrain=ytrain,\n",
    "                                             model=modelo_base,\n",
    "                                             param_grid=param_grid,\n",
    "                                             scoring='f1',\n",
    "                                             refit='f1',\n",
    "                                             cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tunned_lightGBM(X, y, \n",
    "                          learning_rate,\n",
    "                          min_child_samples, \n",
    "                          n_estimators, \n",
    "                          num_leaves, \n",
    "                          n_iter, \n",
    "                          n_splits=10):\n",
    "    \n",
    "    # Transformador de Colunas\n",
    "    ct = ColumnTransformer([(\"ordinal\", OrdinalEncoder(), ['Geography','Gender','CreditScore_new', 'Age_new', 'Tenure_new', 'Balance_new','EstimatedSalary_new']),\n",
    "                        (\"scaler\", RobustScaler(), ['CreditScore','Age','Tenure','Balance', 'NumOfProducts','EstimatedSalary','mean_y', 'LTV'])],remainder='passthrough')\n",
    "    \n",
    "    # Preprocessing e modelo\n",
    "    prep_pipeline = Pipeline([('ct',ct),('smt', smt)])\n",
    "    model = lgb.LGBMClassifier(objective='binary',\n",
    "                               learning_rate = learning_rate,\n",
    "                               min_child_samples = min_child_samples,\n",
    "                               n_estimators = n_estimators,\n",
    "                               num_leaves = num_leaves\n",
    "                               )\n",
    "                         \n",
    "    X = pd.DataFrame(prep_pipeline.fit_resample(Xtrain, ytrain)[0], columns=Xtrain.columns)\n",
    "    y = pd.DataFrame(prep_pipeline.fit_resample(Xtrain, ytrain)[1])\n",
    "\n",
    "    # Dicionário de metricas\n",
    "    resultados = {'ACC_MEAN': [],\n",
    "                  'ACC_STD': [],\n",
    "                  'KAPPA_MEAN': [],\n",
    "                  'KAPPA_STD': [],\n",
    "                  'RECALL_MEAN': [],\n",
    "                  'RECALL_STD': [],\n",
    "                  'F1_MEAN': [],\n",
    "                  'F1_STD': [],\n",
    "                  'PRECISION_MEAN': [],\n",
    "                  'PRECISION_STD': [] }\n",
    "    \n",
    "    # cross-validiação\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    # resultado\n",
    "    acc = []\n",
    "    kappa = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    precision = []\n",
    "    for linhas_treino, linhas_valid in skf.split(X, y):\n",
    "\n",
    "        X_treino, X_valid = X.iloc[linhas_treino], X.iloc[linhas_valid]\n",
    "        y_treino, y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]\n",
    "\n",
    "        model.fit(X_treino, y_treino)\n",
    "        pred = model.predict(X_valid)\n",
    "        Acc = accuracy_score(y_valid, pred)\n",
    "        Kappa =  cohen_kappa_score(y_valid, pred)\n",
    "        Recall = recall_score(y_valid, pred)\n",
    "        F1 = f1_score(y_valid, pred)\n",
    "        Precision = precision_score(y_valid, pred)\n",
    "        acc.append(Acc)\n",
    "        kappa.append(Kappa)\n",
    "        recall.append(Recall)\n",
    "        f1.append(F1)\n",
    "        precision.append(Precision)\n",
    "\n",
    "    resultados['ACC_MEAN'].append(np.mean(acc))\n",
    "    resultados['ACC_STD'].append(np.std(acc))\n",
    "    resultados['KAPPA_MEAN'].append(np.mean(kappa))\n",
    "    resultados['KAPPA_STD'].append(np.std(kappa))\n",
    "    resultados['RECALL_MEAN'].append(np.mean(recall))\n",
    "    resultados['RECALL_STD'].append(np.std(recall))\n",
    "    resultados['F1_MEAN'].append(np.mean(f1))\n",
    "    resultados['F1_STD'].append(np.std(f1))\n",
    "    resultados['PRECISION_MEAN'].append(np.mean(precision))\n",
    "    resultados['PRECISION_STD'].append(np.std(precision))\n",
    "\n",
    "    # retrain over all data\n",
    "    model = model.fit(X, y)\n",
    "\n",
    "    # Painel\n",
    "    painel_df = pd.DataFrame(resultados).T\n",
    "    return painel_df, model\n",
    "\n",
    "# Treinando modelo tunnado\n",
    "painel, modelo_tunned = train_tunned_lightGBM(X=Xtrain, \n",
    "                                       y=ytrain,learning_rate=best_params['learning_rate'],\n",
    "                                                min_child_samples=best_params['min_child_samples'], \n",
    "                                                n_estimators=best_params['n_estimators'] , \n",
    "                                                num_leaves=best_params['num_leaves'],   \n",
    "                                                n_iter=5)\n",
    "\n",
    "# painel de metricas\n",
    "painel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que o modelo base obteve melhor F1 score com o Recall se mantendo muito proximo. \n",
    "Dessa forma serguiremos como o modelo_base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância das variáveis\n",
    "from scikitplot.estimators import plot_feature_importances\n",
    "\n",
    "# Variaveis\n",
    "variaveis = Xtrain.columns.to_list()\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plot_feature_importances(model['model'], feature_names= variaveis, x_tick_rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos observar que a variável LTV foi a variável mais relevante na modelagem do nosso problema. Sendo os 3 principais fatores abaixo:\n",
    "       - Score de crédito do cliente.\n",
    "       - E o life time value do cliente.\n",
    "       - A idade do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "\n",
    "# Predictions\n",
    "pred = model.predict(Xtest)\n",
    "\n",
    "# Plot\n",
    "plot_confusion_matrix(ytest, pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curves\n",
    "from scikitplot.estimators import plot_learning_curve\n",
    "\n",
    "#  Estrátegia de cross-validation \n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "plot_learning_curve(model, Xtest, ytest, cv=skf, scoring='f1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap values"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python portfolio-env",
   "language": "python",
   "name": "portfolio-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
